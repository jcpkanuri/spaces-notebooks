{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":"\n<div id=\"singlestore-header\" style=\"display: flex; background-color: rgba(209, 153, 255, 0.25); padding: 5px;\">\n    <div id=\"icon-image\" style=\"width: 90px; height: 90px;\">\n        <img width=\"100%\" height=\"100%\" src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/header-icons/notes.png\" />\n    </div>\n    <div id=\"text\" style=\"padding: 5px; margin-left: 10px;\">\n        <div id=\"badge\" style=\"display: inline-block; background-color: rgba(0, 0, 0, 0.15); border-radius: 4px; padding: 4px 8px; align-items: center; margin-top: 6px; margin-bottom: -2px; font-size: 80%\">SingleStore Notebooks</div>\n        <h1 style=\"font-weight: 500; margin: 8px 0 0 4px;\">Database Performance Troubleshoot Notebook</h1>\n    </div>\n</div>"},{"attachments":{},"cell_type":"markdown","metadata":{},"source":"<table style=\"border: 0; border-spacing: 0; width: 100%; background-color: #03010D\"><tr>\n    <td style=\"padding: 0; margin: 0; background-color: #03010D; width: 33%; text-align: center\"><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-vertical.png\" style=\"height: 200px;\"/></td>\n    <td style=\"padding: 0; margin: 0; width: 66%; background-color: #03010D; text-align: right\"><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-jupyter.png\" style=\"height: 250px\"/></td>\n</tr></table>\n\n"},{"attachments":{},"cell_type":"markdown","metadata":{"language":"sql"},"source":"\n## Intro\n\n<p class=\"has-text-justified\">\n    Introducing a powerful Python script designed to ease performance analysis tasks for database management.\n</p>\n    \n<ol>\n    <li>This script loads query information from csv file exposed on public URL</li>\n    <li>Executes SQL queries against selected database</li>\n    <li>Exports results to searchable html tables and uploads archive of generated html files with index into stage area</li>\n    <li>Handles Stage Area operations using singlestore python client which uses SingleStore Management API</li>\n    <li>Simplifying complex tasks, this script is essential for streamlining workflows for administrators and developers alike</li>\n</ol>\n\n\n## What you will learn in this notebook:\n\n1. How to read a csv and load data into pandas dataframes[Python] Download DB_PERFORMANCE_TROUBLESHOOT_QUERIES.csv file from url\n2. Execute queries and export result into html files [Python]\n4. Use of SingleStore client for db operations and stage area [Python]\n\n\n## What benefits do you get out of using the notebook.\n\n1. User will be able to run most used performance checks\n2. Results are exported into HTML for better view\n3. Along with analysis of known scenarios, script also provides background and possible actions to take\n\n\n\n## Questions?\n\nReach out to us through our [forum](https://www.singlestore.com/forum).\n"},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-02-22T13:36:58.180760Z","iopub.status.busy":"2024-02-22T13:36:58.180472Z","iopub.status.idle":"2024-02-22T13:36:58.200707Z","shell.execute_reply":"2024-02-22T13:36:58.199997Z","shell.execute_reply.started":"2024-02-22T13:36:58.180744Z"},"language":"sql"},"source":"### Pre-requisites\n\nWe will need below parameters to proceed.\n\n\n\n<ol type=\"A\">\n    <li>SingleStore Management API KEY. Follow this <a href=\"https://docs.singlestore.com/cloud/reference/management-api/\">link</a> for API Key </li>\n    <li>Directory Path of Stage Area ( Target location to upload archive )</li>\n    <li>URL to download csv file</li>\n    <li>URL of result template directory</li>\n</ol>\n\n<p>\n    Note: You may use the \n    <ul>\n        <li><a href=\"https://s2-garageutils.s3.amazonaws.com/DB_PERFORMANCE_TROUBLESHOOT_QUERIES.csv\">DB_PERFORMANCE_TROUBLESHOOT_QUERIES.csv</a> as template to add up your queries.</li>\n    <li><a href=\"https://s2-garageutils.s3.amazonaws.com/templates\">templates</a> as templates  for results</li>\n    </ul>\n</p>\n<p>\n    For simplicity of demo, here we are using a public accessible URL, you have to adapt access pattern to suit your needs.\n</p>    \n\nCSV File structure\n\n<table class=\"table is-bordered is-narrow\">\n<th>\n     <td>QueryID</td>\n     <td>QueryName</td>\n     <td>QueryTxt</td>\n</th>\n</table>\n"},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-02-20T07:41:10.681549Z","iopub.status.busy":"2024-02-20T07:41:10.681297Z","iopub.status.idle":"2024-02-20T07:41:10.690244Z","shell.execute_reply":"2024-02-20T07:41:10.689441Z","shell.execute_reply.started":"2024-02-20T07:41:10.681533Z"},"language":"sql"},"source":"**Note** To enable logs\n\n - Modify 'set_logging_enabled(False)' to 'set_logging_enabled(True)' in code below\n\n\n"},{"cell_type":"code","execution_count":null,"metadata":{"language":"python","trusted":true},"outputs":[],"source":"import io\nimport tarfile\nimport time\nimport logging\nimport getpass\nimport os\n\nimport pandas as pd\nimport singlestoredb as s2\n\nfrom pathlib import Path\nfrom urllib.request import urlopen\nfrom urllib.error import HTTPError\nfrom datetime import datetime\n\nfrom IPython.display import display, HTML\n\nquery_data_url = \"https://s2-garageutils.s3.amazonaws.com/DB_PERFORMANCE_TROUBLESHOOT_QUERIES.csv\"\ntemplate_url_base = 'https://s2-garageutils.s3.amazonaws.com/templates/'\nstage_folder_path = 'DBPERF-REPORT'\n\nmy_timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\nmy_db_conn_url = os.getenv('SINGLESTOREDB_URL')\ndatabase_name = my_db_conn_url[(my_db_conn_url.rfind('/') + 1):]\nlocal_output_dir_suffix = '_' + my_timestamp + '_PERF_REPORT'\n\nempty_result_table = '<p class=\"mb-3 mt-3\" style=\"text-align:center;color:blue;\">No Matching Records Found</p>'\nresult_table_html_classes = 'table table-striped table-bordered table-responsive my-2 px-2'\n\nWORKGROUP_ID = os.getenv('SINGLESTOREDB_WORKSPACE_GROUP')\n\ns2_workgroup_stage = None\ns2_workspace_name = None\n\n\ndef show_warn(warn_msg):\n    \"\"\"\n    Display a warning message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    warn_msg : str\n        The warning message to display.\n    \"\"\"\n    display(HTML(f'''<div class=\"alert alert-block alert-warning\">\n    <b class=\"fa fa-solid fa-exclamation-circle\"></b>\n    <div>\n        <p><b>Action Required</b></p>\n        <p>{warn_msg}</p>\n    </div>\n</div>'''))\n\n\ndef show_error(error_msg):\n    \"\"\"\n    Display an error message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    error_msg : str\n        The error message to display.\n    \"\"\"\n    display(HTML(f'''<div class=\"alert alert-block alert-danger\">\n    <b class=\"fa fa-solid fa-exclamation-triangle\"></b>\n    <div>\n        <p><b>Error</b></p>\n        <p>{error_msg}</p>\n    </div>\n</div>'''))\n\n\ndef show_success(success_msg):\n    \"\"\"\n    Display a success message in a formatted HTML alert box.\n\n    Parameters\n    ----------\n    success_msg : str\n        The success message to display.\n    \"\"\"\n    display(HTML(f'''<div class=\"alert alert-block alert-success\">\n    <b class=\"fa fa-solid fa-check-circle\"></b>\n    <div>\n        <p><b>Success</b></p>\n        <p>{success_msg}</p>\n    </div>\n</div>'''))\n\n\ndef execute_query(dbcon, query_txt):\n    \"\"\"\n    Execute a SQL query on the specified database connection.\n\n    Parameters\n    ----------\n    dbcon : connection\n        The database connection object.\n    query_txt : str\n        The SQL query to execute.\n\n    Returns\n    -------\n    list\n        A list of rows returned by the query.\n    \"\"\"\n    try:\n        with dbcon.cursor() as cur:\n            cur.execute(query_txt)\n        return cur.fetchall()\n    except Exception as e:\n        logging.error(f\"Failed to execute query: {e}\")\n        raise Exception('Failed to execute query')\n\n\ndef make_tarfile(output_filename, source_dir):\n    \"\"\"\n    Create a tar.gz archive of a directory.\n\n    Parameters\n    ----------\n    output_filename : str\n        The name of the output archive file.\n    source_dir : str\n        The path to the directory to archive.\n\n    Returns\n    -------\n    bool\n        True if the archive was created successfully, False otherwise.\n    \"\"\"\n    try:\n        with tarfile.open(output_filename, \"w:gz\") as tar:\n            tar.add(source_dir, arcname=os.path.basename(source_dir))\n        time.sleep(2)\n        file_stats = os.stat(output_filename)\n        logging.info(f'{output_filename} has size {(file_stats.st_size / (1024 * 1024))} mb')\n        return True\n    except Exception as e:\n        logging.error(f'Failed to create archive: {e}')\n        raise Exception(f'Failed to create archive: {e}')\n\n\ndef generate_html_list(links):\n    \"\"\"\n    Generate an HTML ordered list from a comma-separated list of links.\n\n    Parameters\n    ----------\n    links : str\n        A comma-separated list of links.\n\n    Returns\n    -------\n    str\n        The HTML formatted ordered list.\n    \"\"\"\n    if 'nan' == links:\n        return ''\n\n    html_list = '<ol>'\n    for item in links.split(','):\n        html_list += f'<li><a href=\"{item}\">{item}</a></li>'\n    html_list += '</ol>'\n    return html_list\n\n\ndef fetch_url_content(url):\n    \"\"\"\n    Fetch the content of a URL.\n\n    Parameters\n    ----------\n    url : str\n        The URL to fetch.\n\n    Returns\n    -------\n    str\n        The content of the URL.\n    \"\"\"\n    try:\n        with urlopen(url) as response:\n            if response.status == 200:\n                my_bytes = response.read()\n                file_content = my_bytes.decode(\"utf8\")\n                return file_content\n    except HTTPError as e:\n        logging.error(f'Failed to read {url} - HTTP error code: {e.code} reason: {e.reason}')\n        raise Exception(f'Failed to read {url} - HTTP error code: {e.code} reason: {e.reason}')\n\n\ndef load_query_data(url):\n    \"\"\"\n    Load CSV data from a URL into a pandas DataFrame.\n\n    Parameters\n    ----------\n    url : str\n        The URL of the CSV file.\n\n    Returns\n    -------\n    pandas.DataFrame\n        The loaded DataFrame.\n    \"\"\"\n    csv_file_content = fetch_url_content(url)\n    csv_df = pd.read_csv(io.StringIO(csv_file_content), sep=\",\",\n                         dtype={'QueryID': int, 'QueryName': str, 'QueryTxt': str, 'QueryParams': str})\n    csv_df.sort_values(by=['QueryID'], inplace=True)\n    return csv_df\n\n\ndef set_logging_enabled(enabled):\n    \"\"\"\n    Set the logging level based on the enabled flag.\n\n    Parameters\n    ----------\n    enabled : bool\n        True to enable logging, False to disable it.\n    \"\"\"\n    if enabled:\n        logging.getLogger().setLevel(logging.INFO)\n    else:\n        logging.getLogger().setLevel(logging.CRITICAL)\n\n\ndef verify_stage_area():\n    \"\"\"\n    Verify the existence and writability of a stage area.\n\n    Returns\n    -------\n    bool\n        True if the stage area is valid, False otherwise.\n    \"\"\"\n    try:\n        global s2_workgroup_stage, s2_workspace_name\n        my_workspace_mngr = s2.manage_workspaces(management_api_key)\n        workspace_group = my_workspace_mngr.get_workspace_group(WORKGROUP_ID)\n        s2_workspace_name = my_workspace_mngr.get_workspace(os.environ['SINGLESTOREDB_WORKSPACE']).name\n        stage_obj = workspace_group.stage.mkdir(stage_path=stage_folder_path, overwrite=False)\n        logging.info(\n            f'Stage Path {stage_folder_path} is ok. Is Directory: {stage_obj.is_dir()}. Is Writeable: {stage_obj.writable}')\n        if stage_obj.is_dir() and stage_obj.writable:\n            s2_workgroup_stage = workspace_group.stage\n            logging.info(f'stage is valid: {s2_workgroup_stage is not None}')\n            return True\n        else:\n            logging.error(f'As provided path is neither directory nor writable.')\n            return False\n    except Exception as stage_ex:\n        logging.error(f'Stage Path Verification Failed. {stage_ex}')\n        return False\n\n\ndef generate_stage_link(stg_path, curr_file_path):\n    \"\"\"\n    Generate an HTML link to a stage area.\n\n    Parameters\n    ----------\n    stg_path : str\n        The path to the stage area.\n    curr_file_path : str\n        The current file path.\n\n    Returns\n    -------\n    str\n        The HTML formatted link.\n    \"\"\"\n    url = f\"https://portal.singlestore.com/organizations/{os.environ['SINGLESTOREDB_ORGANIZATION']}/workspaces/{os.environ['SINGLESTOREDB_WORKSPACE_GROUP']}#stage/{stg_path}\"\n    return f\"\"\"<div style=\\\"text-align:center;margin-top:5px; margin-bottom:5px;\\\">\n                 File Uploaded to STAGE &nbsp;&nbsp;&nbsp;&nbsp; <a href='{url}'> {curr_file_path} </a>\n               </div>\"\"\"\n\n\nif __name__ == '__main__':\n\n    if connection_url.endswith('/'):\n        show_warn('Database not selected. Please select from dropdown in top of web page')\n    else:\n        management_api_key = getpass.getpass(prompt='Enter Single Store Cloud API KEY')\n        execution_success = True\n        final_file_path = None\n        error_msg = None\n        try:\n            set_logging_enabled(False)\n            if verify_stage_area():\n\n                conn = s2.connect(results_type='dict')\n                logging.info('Database Connection establised')\n                queries_df = load_query_data(url=query_data_url)\n                logging.info('Query Data loaded')\n                local_dir_path = (s2_workspace_name + local_output_dir_suffix)\n                path = Path(local_dir_path)\n                path.mkdir(exist_ok=True)\n\n                for idx, row in queries_df.astype(str).iterrows():\n                    query_id = row['QueryID']\n                    query_name = row['QueryName']\n                    query = row['QueryTxt']\n\n                    logging.debug(f'about to execute {query_name}')\n\n                    try:\n                        result = execute_query(conn, query)\n\n                        logging.info(f\"Fetched query ID: {query_id} NAME: {query_name}\")\n                        template = fetch_url_content(template_url_base + 'Result-' + str(query_id) + '.template.html')\n                        if not result:\n                            logging.warning(f\"Query result is empty for query '{query_name}'\")\n                            final_content = template.replace('rstable', empty_result_table)\n\n                            # display(HTML(final_content))\n\n                        else:\n                            result_df = pd.DataFrame(result)\n                            # capitalize column names\n                            result_df.columns = map(str.upper, result_df.columns)\n                            result_table_id = 'rstbl'\n                            result_table_content = result_df.to_html(table_id=result_table_id,\n                                                                     index=False,\n                                                                     classes=result_table_html_classes)\n\n                            final_content = template.replace('rstable', result_table_content)\n\n                            # display(HTML(final_content))\n\n                        report_file = f'{local_dir_path}/{query_id}.html'\n\n                        with open(report_file, 'w') as writer:\n                            writer.write(final_content)\n\n                    except Exception as e:\n                        logging.error(f\"Error executing query ID: {query_id}, NAME: {query_name}: {e}\")\n                        logging.exception(\"Exception details\")\n                        show_warn(f\"Error executing query ID: {query_id}, NAME: {query_name}\")\n\n                    logging.info(f'process completed for ID:{query_id} Name:{query_name}')\n\n                logging.info('Result Pages are generated')\n\n                index_file = f'{local_dir_path}/index.html'\n\n                index_file_content = fetch_url_content(template_url_base + 'index.template.html')\n\n                with open(index_file, 'w') as writer:\n                    writer.write(str(index_file_content))\n\n                logging.info('Index Page are generated')\n\n                zip_file_path = s2_workspace_name + '_PERF_REPORT_' + my_timestamp + '.tar.gz'\n\n                zip_success = make_tarfile(zip_file_path, local_dir_path)\n\n                logging.info('archive created')\n\n                if zip_success:\n                    try:\n                        uploaded_obj = s2_workgroup_stage.upload_file(local_path=zip_file_path,\n                                                                      stage_path=f'{stage_folder_path}/{zip_file_path}')\n                        logging.info(f'Upload success. Path: {uploaded_obj.abspath()} ')\n                        print(f'File uploaded to STAGE AREA: {uploaded_obj.abspath()}')\n                        logging.info('Upload success')\n                        final_file_path = zip_file_path\n                        os.remove(zip_file_path)\n                        logging.info('Local archive file removed')\n                        logging.info('about to clean previous generated files in local dir')\n                        for root, dirs, files in os.walk(local_dir_path):\n                            for file in files:\n                                if file.endswith('.html'):\n                                    os.remove(os.path.join(root, file))\n                        os.rmdir(local_dir_path)\n                        logging.info('Local files cleaned')\n                    except Exception as e:\n                        execution_success = False\n                        logging.error(f'Failed during upload process{e}')\n                        error_msg = 'File Upload failed'\n\n                else:\n                    logging.error('Failed to create archive')\n                    execution_success = False\n                    error_msg = 'Failed to create archive'\n\n            else:\n                logging.info(\"Stage Area Verification Failed. Exiting.\")\n                print('Script execution Failed')\n                execution_success = False\n                error_msg = 'Failed to create missing stage area path or it is not writeable'\n        except Exception as e:\n            execution_success = False\n            logging.error(f\"An error occurred: {e}\")\n            logging.exception(\"Exception details\")\n            error_msg = f'Exception occured. {str(e)}'\n\n        if execution_success:\n            show_success(generate_stage_link(stage_folder_path, final_file_path))\n        else:\n            show_error(error_msg)\n\n        logging.info(f'Script execution completed sucessfully: {execution_success}')\n"},{"attachments":{},"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2024-02-20T09:10:37.588406Z","iopub.status.busy":"2024-02-20T09:10:37.588115Z","iopub.status.idle":"2024-02-20T09:10:37.602107Z","shell.execute_reply":"2024-02-20T09:10:37.601440Z","shell.execute_reply.started":"2024-02-20T09:10:37.588388Z"},"language":"sql"},"source":"**Important NOTE** \n\n - Actions suggested suit most of performance improvement scenarios, Still we would encourage to test and verify before applying on prod environemnts\n - To use notebook as scheduled one, we have to modify python code to refer configuration from table instead of user input "},{"attachments":{},"cell_type":"markdown","metadata":{"language":"sql","trusted":true},"source":"<div id=\"singlestore-footer\" style=\"background-color: rgba(194, 193, 199, 0.25); height:2px; margin-bottom:10px\"></div>\n<div><img src=\"https://raw.githubusercontent.com/singlestore-labs/spaces-notebooks/master/common/images/singlestore-logo-grey.png\" style=\"padding: 0px; margin: 0px; height: 24px\"/></div>"}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.6"},"singlestore_cell_default_language":"python","singlestore_connection":{"connectionID":"0ca7deeb-93e9-4ed8-9c77-cc9914997899","defaultDatabase":"citizix_db"}},"nbformat":4,"nbformat_minor":4}